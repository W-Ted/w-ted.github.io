
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">
    <title>GScream</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

        <!--FACEBOOK-->
    <meta property="og:image" content="./images/udcnerf_teaser.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="682">
    <meta property="og:image:height" content="682">
    <meta property="og:type" content="website" />
    <meta property="og:url" content=""/>
    <meta property="og:title" content="GScream" />
    <meta property="og:description" content="Project page for Learning 3D Geometry and Feature Consistent Gaussian Splatting for Object Removal." />

        <!--TWITTER-->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="GScream" />
    <meta name="twitter:description" content="Project page for Learning 3D Geometry and Feature Consistent Gaussian Splatting for Object Removal." />
    <!-- <meta name="twitter:image" content="https://jonbarron.info/mipnerf/img/rays_square.png" /> -->


<!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
  <!-- <link rel="icon" type="image/png" href="img/seal_icon.png"> -->
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>

    <style>
        .left_img_right_video {
          display: flex;
        }
        
        .left_img_right_video img {
            width: 50%;
            margin-right: 5pt;
            margin-bottom: 5pt;
        }
        .left_img_right_video video {
            width: 50%;
            margin-bottom: 5pt;
        }
    </style>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <!-- <b>GBi-Net</b>: A Multiscale Representation <br> for Anti-Aliasing Neural Radiance Fields</br>  -->
                
                <!-- Learning <font color="#5364cc">U</font>nified <font color="#5364cc">D</font>ecompositional and <font color="#5364cc">C</font>ompositional <font color="#5364cc">NeRF</font> for <br> Editable Novel View Synthesis</br> -->
                Learning 3D Geo<font color="#5364cc">m</font>etry and Fe<font color="#5364cc">a</font>ture <font color="#5364cc">C</font>onsistent <font color="#5364cc">G</font>aussian <font color="#5364cc">S</font>platting <br> for Object <font color="#5364cc">Re</font>moval </br>
                <small>
                    ArXiv 2024
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://w-ted.github.io/">
                          Yuxin Wang
                        </a>
                        </br>HKUST
                    </li>
                    <li>
                        <a href="https://wuqianyi.top/">
                          Qianyi Wu
                        </a>
                        </br>Monash University
                    </li>
                    <li>
                        <a href="http://www.cad.zju.edu.cn/home/gfzhang/">
                          Guofeng Zhang
                        </a>
                        </br>Zhejiang University
                    </li>
                    <li>
                        <a href="https://www.danxurgb.net/">
                          Dan Xu
                        </a>
                        </br>HKUST
                    </li>
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <!-- <a href="link"> -->
                            <a href="https://arxiv.org/abs/2308.02840" target="_blank" class="imageLink"><img
                                src="https://www.filepicker.io/api/file/XQvDkgbsRiiPh8VSZ8wu" , width="50%"></a>
                            <a href="https://arxiv.org/abs/2308.02840" target="_blank"><h4><strong>Paper</strong></h4></a>
                            </a>
                        </li>
    
                        <!-- <li>
                            <a href="https://github.com/W-Ted/GScream" target="_blank" class="imageLink"><img
                                src="./imgs/icon_github.png" , width="50%"></a>
                            <a href="https://github.com/W-Ted/GScream" target="_blank"><h4><strong>Code</strong></h4></a>
                        </li> -->
                    </ul>
                </div>
        </div>


        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <image src="./imgs/pipeline.png" class="img-responsive" alt="overview" style="width: 98%;"><br>
                    An overview of the proposed unified decompositional and compositional NeRF (<strong><font color="#5364cc">GScream</font></strong>) framework for joint novel view synthesis and scene editing. It has two stages. In the first stage (the coarse stage), it learns a guidance radiance field for guiding point sampling. In the second stage (the fine stage), we learn scene decomposition via learnable object codes and two novel decomposition schemes: <b>(i)</b> the 3D one-shot object radiance activation regularization and <b>(ii)</b> color inpaiting handling ambiguous generation in occluded background areas. The scene composition is achieved by using one-hot activation weights for different object-level radiance fields learned in the decomposition stage. The decomposition allows scene editing and the composition enables novel view synthesis in the unified framework. 
            </div>
        </div>
        <br> -->


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
            <h3>
                Object Removal Demos
            </h3>

            <div class="section">
                <!-- <center> -->
                <p><b>Left:</b> Sampled image & mask. <b>Right:</b> Novel view synthesis with object removed. 
                </p>
                <!-- </center> -->
            </div>
            
            <!-- demo 1 -->
            <!-- <td style="padding:20px;width:25%;vertical-align:middle">
                <video id="v11" width="48.5%" autoplay loop muted controls>
                    <source src="imgs/nvs_01.png" type="video/mp4" />
                </video>
            </td>
            <td width="75%" valign="middle">
                <video id="v12" width="48.5%" autoplay loop muted controls>
                    <source src="imgs/1.mp4" type="video/mp4" />
                </video>
            </td><br><br> -->


            <div class="left_img_right_video">
                <img src="imgs/9.jpg" alt="img">
                <video autoplay loop muted controls>
                    <source src="imgs/9.mp4" />
                </video>
            </div>

            <div class="left_img_right_video">
                <img src="imgs/12.jpg" alt="img">
                <video autoplay loop muted controls>
                    <source src="imgs/12.mp4" />
                </video>
            </div>

            <div class="left_img_right_video">
                <img src="imgs/book.jpg" alt="img">
                <video autoplay loop muted controls>
                    <source src="imgs/qqbook.mp4" />
                </video>
            </div>

            <div class="left_img_right_video">
                <img src="imgs/qq10.jpg" alt="img">
                <video autoplay loop muted controls>
                    <source src="imgs/qq10.mp4" />
                </video>
            </div>

            <div class="left_img_right_video">
                <img src="imgs/1.jpg" alt="img">
                <video autoplay loop muted controls>
                    <source src="imgs/1.mp4" />
                </video>
            </div>

            <div class="left_img_right_video">
                <img src="imgs/7.jpg" alt="img">
                <video autoplay loop muted controls>
                    <source src="imgs/qq7.mp4" />
                </video>
            </div>


        </div><br>




        <div class="row">
                <div class="col-md-8 col-md-offset-2">
                <h3>
                    <!-- Samples - Object Manipulation Videos -->
                    Supplementary Video
                </h3>

                <div class="section">
                  <!-- <center> -->
                  <p>Please refer to our supplementary video for more comparison and ablation studies. (It may take a few seconds to load. )
                  </p>
                  <!-- </center> -->
                </div>

                <!-- <td style="padding:20px;width:25%;vertical-align:middle">
                    <video id="v11" width="48.5%" autoplay loop muted controls>
                        <source src="imgs/toy.mp4" type="video/mp4" />
                    </video>
                </td>
                <td width="75%" valign="middle">
                    <video id="v12" width="48.5%" autoplay loop muted controls>
                        <source src="imgs/scan.mp4" type="video/mp4" />
                    </video>
                </td> -->
                <td style="padding:20px;width:25%;vertical-align:middle">
                    <video id="v11" width="100%" autoplay loop muted controls style="border: 1px solid gainsboro;">
                        <source src="imgs/preface_v3_arxiv_modi.mp4" type="video/mp4" />
                    </video>
                </td>
                <br><br>

                <!-- <div class="section">
                  <center>
                  <p>Comparisons with the state-of-the-art method ObjectNeRF. 
                  </p>
                  </center>
                </div> -->
            </div><br>

<!-- 
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Samples - Novel View Synthesis
                </h3>

                <image src="./imgs/nvs_01.png" class="img-responsive" alt="overview" style="width: 98%;"><br>
                <image src="./imgs/nvs_02.png" class="img-responsive" alt="overview" style="width: 98%;"><br>

                <div class="section">
                  <center>
                  <p>Comparisons with state-of-the-art methods: ObjectNeRF and ObjectSDF. 
                  </p>
                  </center>
                </div>
            </div><br>

            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Samples - Background/Object Decomposition
                </h3>

                <div style="display: flex;">
                    <img src="./imgs/decomp_toy.png" style="width: 45%; margin-right: 30px;" />
                    <img src="./imgs/decomp_scan.png" style="width: 45%; margin-left: 30px;" />
                </div><br>

                <div class="section">
                  <center>
                  <p>Comparisons with ObjectNeRF and ground truth on ToyDesk-scene2 and ScanNet-0113. 
                  </p>
                  </center>
                </div>
                
            </div><br>

            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Samples - Editing
                </h3>
                <image src="./imgs/supp_edit.png" class="img-responsive" alt="overview" style="width: 96%;">

                <div class="section">
                  <center>
                  <p>Editing results on both ToyDesk and ScanNet datasets. 
                  </p>
                  </center>
                </div>
                
            </div><br>

        </div> -->

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify"> This paper tackles the intricate challenge of object removal to update the radiance field using the 3D Gaussian Splatting. The main challenges of this task lie in the preservation of geometric consistency and the maintenance of texture coherence in the presence of the substantial discrete nature of Gaussian primitives. We introduce a robust framework specifically designed to overcome these obstacles. The key insight of our approach is the enhancement of information exchange among visible and invisible areas, facilitating content restoration in terms of both geometry and texture. Our methodology begins with optimizing the positioning of Gaussian primitives to improve geometric consistency across both removed and visible areas, guided by an online registration process informed by monocular depth estimation. Following this, we employ a novel feature propagation mechanism to bolster texture coherence, leveraging a cross-attention design that bridges sampling Gaussians from both uncertain and certain areas. This innovative approach significantly refines the texture coherence within the final radiance field. Extensive experiments validate that our method not only elevates the quality of novel view synthesis for scenes undergoing object removal but also showcases notable efficiency gains in training and rendering speeds.
                </p>
            </div>
        </div>


          <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <pre>@article{wang2024gscream,
     title={GScream: 3D Geometry and Feature Consistent Gaussian Splatting for Object Removal},
     author={Wang, Yuxin and Wu, Qianyi and Zhang Guofeng and Xu, Dan},
     journal={arXiv preprint arXiv:},
     year={2024}
     }
                </pre>
            </div>
        </div>
        


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                    <!-- Our code follows several awesome repositories such as 
                    <a href="https://github.com/harlanhong/CVPR2022-DaGAN">DaGAN</a>,
                    <a href="https://github.com/AliaksandrSiarohin/first-order-model">FOMM</a>,
                    We appreciate them for making their codes available to public.
                    <br>
                    This research is supported in part by HKUST-SAIL joint research funding, 
                    the Early Career Scheme of the Research Grants Council (RGC) of 
                    the Hong Kong SAR under grant No. 26202321 and HKUST Startup Fund No. R9253. -->
                    <!-- <br> -->
                    The website template was borrowed from <a href="https://jonbarron.info/">Jon Barron</a> <a href="https://jonbarron.info/mipnerf/">Mip-NeRF</a>.
                    <br>
                    <br>
                </p>
            </div>
        </div>
    </div>
</body>
</html>

